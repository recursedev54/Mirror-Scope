that so he's a systems engineer for voxley they're innovating on voxel engine technology the ability to actually make games for example and other interesting 3D projects just using pure voxels right so I think that's great you know lots of companies have tried and failed in the past to make voxels pure voxel engine Tech work right so they're trying to crack the code there and then he has a talk called optimism and design I don't want to spoil it so uh his first time talking his first time speaker let's you know be warm and welcoming a big round of applause to Davis Morley all right so I do want to clarify although at voxley we do work on like pure voxel engines I'm going to be covering a more rasterized version of voxel engines uh for the sake of the talk but that works too all right well there you go there you go all right so today I'm going to talk about optimism and Design so I want to take you all through the process of creating a voxel engine together and so we have to start with the basics what even is a voxel this can be a pretty contentious idea if anyone's had an annoying conversation about pixels before just take whatever you think about pixels and apply that to 3D and you're right okay um but I'm also going to Define it for the sake of this time you know uh let's just say our voxel is a point in a 3D grid all right should a cell in this uniform grid well what space does our grid exist in what kind of world does our voxel exist in well we know it's a 3D grid so we have three axes X Y and Z let's define our horizontal axes as x and z and our vertical axis as y okay what kind of data should our voxel have well let's say we want a dynamic world we want different kinds of voxels we want variation so let's have some different voxel types what kind of voxels do we want to start with well let's just say we start with stone dirt sand and grass all right but we need a way to uniquely identify these voxels right because we have these four types how do we know which voxel uh our voxel is what we can do is we can assign unique identifiers right so we can assign Stone to one dirt to two sand to three grass to four and then air to zero which is really just the absence of a type okay well what does our box look like in memory let's just say it's an unsigned 16-bit integer all right and it just has this idea so now we have a voxel with its type and a 3D grid and this 3D grid exists in the space but what is our volume what kind of world do we want to have what volume is this single voxel a part of well instead of having one massive world if we think about it voxel engines are normally very localized in their changes when you place and break a single voxel they're very local in scope right even if you have voxels act on their own they're always going to be affecting a very small specific region so instead of having one massive world what we can do is we can break it up into smaller chunks and you might have heard the term chunk before this is where it comes from and now when we change or replace voxels we can be very focused on how we update things we only have to care about the actual region that it's affecting instead of the entire space recontextualizing all of it right what size should these smaller chunks be it's kind of a balancing act right because as a programmer we have to consider how many unique objects we want to reason about in our code and also how large of an area we want to have to recontextualize when we change something well I decided for us for convenience later on so let's just go with the size of 64. and all this means is we have 64 voxels in every direction x y and z or we have a 64 cubed volume or 262 114 or sorry 262 114 voxels so now our voxel world is made out of 64 cubed chunks right well what does our chunk look like in memory right we know what our voxel looks like in memory what does our chunk look like well we might initially go with the idea of using a 3D array where we use a voxel's position to index into a specific voxel that's kind of annoying because whenever we want to refer to a single voxel we'd have to Lug around this position so what we can do is we can take that 3D position and compose into a single digit that we can use to index into a flat array well how do we do that right well to start we can break uh down our index into single axes right X Y and Z and we can compose it from there so let's say we start with X right now we we're just creating our index from X so any addition to X is really just an addition to index plus one to X is just plus one to Index right which means index is only going to be 0 to 64 because we can only have X be 0 to 64 because our chunk size is 64 right and next let's add Z we could have chose y but for the sake of iteration times and cash coherency let's let's say we chose C right so since our chunk size is 64 and X is always going to be in the range of 0 to 64. what we can do is we can add Z to our index without actually affecting our x value our x value is always going to exist and that's 0 to 64 range where whereas our Z can exist in a 0 to 64 times 64 range right so whenever we add 1 to X it's just actually adding one to index and whenever we add 1 to Z it's actually adding 64 to index because Z is going to be multiple of 64. and that way we've we're not creating any extra voxels we're still the same amount of voxels right because we're creating a 3D Volume but we can still extract the parts we care about later on so now we finally add y so we've covered the range of 0 to 64 and then 0 to 64 times 64. so now we can cover the range of 0 to 64 cubed right so now any addition to Y is really uh 64 times 64 in the index so we can compose all together and then we have our finished formula right we have X Y and Z all adding to this formula and we're only affecting specific ranges per type of axis per axis Direction how do we get our index back to 3D position well since we are only affecting specific ranges when we create our index we can also extract those specific ranges when we want to care about a certain axis X Y or Z right we're all together and we can do that by um so since X is actually just 0 to 64. we can see we can just take index with and use the modular operator with 64 and extract that 0 to 64 range and since Z only exists in a range of 0 to 64 squared we can do the same thing where we divide index by 64 then use the same modular operator and then we just repeat that process for y so we have we're still representing a 64 cubed area but we're now able to use a single position or sorry a single in index from this 3D position right so now we can Define what our chunk looks like in memory instead of having that 3D array as before we can just have a single index and a flat array which is really powerful because now we just have this handle to this voxel what about our world well we can take the same concept we had before of taking a 3D position of a voxel and turning that into a single index and apply that to our chunks we can take our chunks 3D position in the world and turn that into a single index into our world's own array of just chunks right and we could do this the same way we did it with 64 before because we knew our chunk size was 64. if we could take the size of our world or the render distance in any given Direction and use that to compose our chunk Index right so that we have everything in memory right we've defined our voxel world what does it really look like on the screen how do we take this and put it on the screen let's start with a single voxel right the simplest form that our engine is going to render right at any given time how is a voxel going to be represented in our world right well for the sake of Simplicity and this is where it's no longer a pure voxel engine so to speak let's just say our voxel is geometrically a cube well how do we draw a cube on the GPU right what we can do is we can take it six faces that make a full cube and break those into triangles so now we can draw 12 triangles for six faces when we add them to all all together we have a completed Cube but what if we're trying what are our triangles made out of though vertices right we have these Corners that we're constructing these triangles out of then constructing these faces out of and then eventually when we combine them all together we have a single Cube so what is our vertex made out of what is the simplest building block that we're using to construct all this information made out of right well let's just say well what information do we really need to convey to the GPU when we're drawing a single voxel well we need an awareness in the world so we need our x y and z and we also need that index and we need that or sorry we also need the ID that we defined earlier of you know dirt Sand Grass so that we can properly texture it when we draw it because we need to know if I'm dirt I want to look like dirt if I'm Stone I want to look like Stone and we can convey that to the GPU with this ID okay so now we can draw a cube or we can draw our voxel finally right we have our vertices we have our triangles our faces how do we do this for the entire world well if we took that same concept of adding six faces for every single voxel that had a type it wouldn't work very well right because what are we really trying to do here we're trying to extract the simplest form the simplest geometric representation of the world that we can and right now if we added six faces for every set of voxel we'd have a lot of occluded faces or invisible faces right so what we can do is instead of adding every single possible phase we only have to add faces that are exposed to air so instead of adding these redundant faces we only extract the parts that we care about we only extract the parts that are ever going to be visible to the camera or the player in this case right this is called naive meshing because we're doing the very first naive thing we're just getting rid of the data that we don't need and holding on to the state that we actually care about so let's do this for every voxel in our chunk so we just go through everything we extract all the faces we need and if we do that long enough maybe we don't add some faces for a single box but if we combine all the actually visible faces we'll have a completed uh representation of our chunk even though it's like a sparse extraction of vertices right great so now we're done right well we just defined what our voxels are in memory we just said how we can render them we can extract the faces we need well it's kind of slow naively meshing a 64 Cube chunk or our chunk size takes around three to five milliseconds on my eight i7 a700k right which isn't you know the best CPU but it's not the worst either when I draw that same test with a simple testing with with a 1024 by 255 by 1024 resolution that contains just a simple flat height map essentially I get around 55 FPS with an RTX 2080 at 720p which sucks right that's really really slow we can do better though with something called greedy meshing so what exactly is greeny meshing greedy meshing is where we take adjacent faces that have the same ID and combine them well how we're able to do this well if we think about what data we're actually uploading to the GPU it's just a position so we know where the voxel is in the world and the IDS that we know how to properly texture it so if we have adjacent faces we can represent that same information with a single face combined because we can just enlarge the area that that single face is covering and also keep that same idea if it if they're all sand they can all still look like sand and we can represent all of them with a single phase that's great but how does it actually work well to start let's just take a 2d slice of our world it's easier to do things in 2D first and then translate them later to 3D and to start we can focus on those sand blocks in the bottom left and then we'll also start growing from the bottom left voxel the bottom left sandal uh voxel so we know we have an ID of three and we can do is let's just say we try to grow this space first vertically right so what we can do is we can look at the voxel above us and if it has the same ID which in this case is three if it's also sand we can grow to it right but if we try to grow vertically again we see that we have air above us or zero right so we can't go vertically anymore because we can't combine the faces because it has a separate type and also air just simply doesn't have a mesh representation so since we can't grow vertically anymore what we can do is try to go horizontally and thankfully the next column since we've grown uh and sorry since our face is too tall we look at the next column that's also too tall and say hey can I mesh to you right and since we all share the same ID we can mesh and that's how we extract this face we essentially start from the bottom left and grow upwards and then horizontally right let's apply this algorithm to the rest of our scene nice it's a really significant reduction in faces you can see that we went from 24 down to 9 in the simple 2D testing if we consider for a second that our actual world is 64 cubed or in our Max slice that we might be doing this on our Max 2D slice is 64 squared it's a really huge reduction in phases down from 24 to 9 if we were just doing naive meshing can we do better though this is something I want to talk about is if you continuously sorry if you continually step back and reevaluate your problem and think there might be a better solution it's a very powerful position to be in and that does require a certain amount of autism you have to think that it's possible for you to do better than you're currently doing that's kind of the theme of this talk well what are we currently limited by we have all this type information right we have sand dirt and these all have their own IDs and we're only able to combine adjacent columns and also only do that by considering the correct IDs right we can only combine sand we can only combine dirt uh to dirt for instance right well what makes up our vertex right our position and our ID but if we think about it right now we're considering the ID when we don't really need to right now we're baking the the ID into our vertices to upload them to the GPU so we can texture them properly but we only really need that ID on the GPU right we're preemptively preparing this data even though we only really need this data on the GPU so instead of preparing it now and meshing what we can do is we can just upload it directly to the GPU so instead of having to consider this on the CPU or local and memory when we're meshing we can just have this type of directly on the GPU and Sample it that way I mean we could also have it be a 3D texture so you can just use your world space position in a in a Shader to look up what type you are and then use that type to texture yourself or we could use a buffer and that has the advantage of maybe being able to run some compression on it like run length encoding right we aren't getting rid of any data we're just moving it around we're just taking the data we had on the CPU when we were meshing and we're moving it to the GPU to sample there right so we're just moving it to where it was actually headed already well where does this leave us right now instead of only having to mesh similar types what we can do is we can mesh all all types together basically because it's become a binary problem no longer do we have to consider the type information when we're meshing because it's on the GPU already we don't have to worry about it anymore it's already there so now what we can do is we can combine every single possible phase we can grow as much or possible ID we can grow as much as possible so you can see we go from the the left scene which was considering type by type to the right thing which is just a binary operation we start from the bottom left we go vertically as much as possible and then we go horizontally as much as possible right so we're we're always continuously reducing uh the amount of work we're doing and we're keeping we're representing the same data though and this requires a step back and kind of reflection that's required to really make sense of this stuff right or to think it's even possible okay but do we still have to work with IDs if it's a binary problem all we need is a binary representation of our scene right if we if we're only binarily considering types we don't have to use that type information we can just use bits right because that's the simplest form of you know a binary operation just zero or one let's think about this for a second right now our chunk is stored in a 3D grid of voxel structs in an array right we should have a single struct per voxel and that and that struct has an ID what we can do instead is we can as a binary representation of our voxel data is just use an array of bits instead of having a single struct per voxel we can just have a single bit per voxel and we can use that to mesh instead right so let's make a bit array first we can take our current index formula and chop off the Y so then we just have x and z and then we can use x and z to index into a specific column and in that column we can bring back y and use that to access a specific voxel at a height so let's say we have an X of 0 and a z of zero we can use that to access the column at 0 0 and we can use a y of let's say three to access the fifth bit there and either set that or either set that to one or zero based on if we're setting a voxel to anything besides air or air right so now that we can let's turn our scene into binary we have this bit of Ray we have one bit per voxel what we can do is we can take any voxel with any type at all and set them to ones and we can set any voxel that has a type of error or zero to zero right and we can see this represented here with white boxes for ones and empty boxes for zeros before we combine our faces though where does 64-bit integers really great at bitwise operations right they're perfect for the single operation comparisons right and if we think about it for a second all we're really doing with our our greedy meshing algorithm from before is we're doing bitwise and we're taking we're growing vertically then when we have that data we go to the next column and say hey do you contain me or more than me do cane do you contain me at least and we can do this All in a single operation now we have these columns as a single object in memory we don't have we don't have to do this voxel by voxel if we can consider it all uh at a column at a time right so we take our first column here we do we skip the process of growing vertically because we already know we have two first set bits right and then we can just grow as we did before by adding that to the next column that we want to grow to so we're really doing the same operations but now it's just a single bit wise and we take our column we go to the next one and we try to end with it and if we can if it contains us or more than us if it has a height equal to or higher than us then we can grow to it and if we continue this process for the rest of our scene we can see that we extract that bottom face the same way we did before if we were to consider it type by type so we're really like capitalizing on the the binary nature of this we can use these bitwise operations to consider 64 voxels at once right so yeah we've we've significantly reduced the amount of operations instead of having to grow voxel by voxel potentially 64 times in our actual scene what we can do is we can consider 64 voxels at one go and then we can continuously do that so it's kind of an exponential problem instead of like if we grew vertically 64 times in one column we would have to go to the next column and when we were when we were trying to grow our face to that we'd have to count another 64 voxels so now we can just do it column by column it's a lot simpler remember it's just one operation right it's very powerful all right but there's a property of voxel worlds that we're ignoring they often have a more complicated 3D scene right they're rarely this flat in nature they're rarely essentially 2D right so we can do is we can add some clouds with an idea of Phi and put five and put them up in the top left corner of our 7x7 test scene if we take that scene and turn it into bits we can see that our the same thing we were doing before with the bitwise and wouldn't work anymore with these 3D or more complicated columns because we can't extract one face per column right we have multiple faces per column potentially now right well we can make our bitwise and uh system work by breaking our current columns down into smaller parts how can we extract the first two set bits here how can we take the max that we were using to compare with before from our current more complicated scene well we can use something that 64-bit integers are also great for intrinsics right they're perfect for this specifically one called trailing zero count this just works on 64-bit integers to start we can take the First Column that we want to extract that bottom mask out of and invert it then we can count the first series of zeros which is our first really our first two set bits inverted which in this case is two right and then we can just construct a new mask based on that series of zeros and now we can use this mask to compare as we were doing before so now we can extract the parts of the column we actually care about and use that to mesh right so we're getting the same results as we did before because we're only using this subset of the column to get to the next set of the bits that we want to mesh we can just we know we already matched the first two bits so we can skip those and then we get the count of zeros between us and the next series of bits and that's case in this case that's three so we can just skip those and then we have an offset of five bits right and then we can repeat the process we used before to extract those two bits right and then we can construct this new mask out of those two bits and use that to me or that to mesh right so we can break down our more complicated column into two parts and individually when we combine the results of them we get our we get our completed scene right if we continue this for the rest of the scene uh you know we have our completed scene it's binary it's fast wow we now have a more complicated scene mesh binarily using bitwise operations and intrinsics right so that's really really fast probably because these 64-bit integers are perfect for that so let's talk about speed whoa that's fast all the greedy meshing times or even our naive meshing which is like our simplest scenario it took around three to five milliseconds for a 64 cubed area I even took those greedy meshing times and I think it was force 32 cubed area but I wasn't sure about the time so I just quadrupled them to make sure that it was accurate um now we're down to 0.12 milliseconds for a 64 cubed area because we've taken our problem that was considering um all of our voxels voxel by voxel and broken it down into do we get column by column or 64 voxels by 64 voxels every single time we've greatly reduced the amount of operations we're doing and not only that these are really really fast operations that we're doing on the CPU they don't take like any Cycles right bitwise and it's like nothing right so if we expand this exponentially it really has huge implications for our world because now we don't have to spend potentially five milliseconds of our you know 6.7 7 milliseconds of frame time if we're targeting 144 fps to mesh a single Chunk we can just you know mesh as many chunks as we want effectively but we could be faster with a simple thread key on my i-78700k we can go from 0.12 milliseconds down to 0.01 milliseconds per 64 Cube Chunk on average and we're able to do this because our chunks are inherently like prepared for a synchronous um work right because all of our voxels are isolated in a single array and all those voxels are isolated in a chunk array so whenever a chunk is being meshed it's only accessing its own data it's never looking to other chunks it's only working on itself so all we have to do is we can create a simple cue system of Chunk indices the same way we took the 3D position and turn it to a single index we can add those indices to a single array and then when the thread wants to do more work it just has to go into this array get that index and say hey mesh me and then from that we can create a unique vertex buffer dedicated to each chunk right so that's how we go from 0.12 milliseconds to 0.01 milliseconds and that's only because I have six cores in my i7 700k instead of you know something more which means 12 threads so that includes the main thread there's another caveat here too though um this only works in our best case scenario when we have at least 12 uh chunks to saturate all of our threads but this is kind of the case you want to optimize for when you're loading new chunks in the world when you have a rolling world and you want to pull in new noise or something that's really your worst case especially if you considered before that five milliseconds you would see them slowly load in but now we can do this in a single frame 12 chunks at a time and 0.12 milliseconds it's really powerful and then if you do have your worst burst case which is where you're meshing only a single chunk per frame it's only going to take 0.12 milliseconds still which isn't going to hurt your frame budget much at all well that's faster so again we went from three to five milliseconds down to 0.01 milliseconds that's a huge reduction in time but we could be even faster if we think about it for a second what are we really doing with our meshing all we're doing is we're telling the GPU where a possible voxel can exist since we moved all the type information that we were before baking in our vertices to the GPU we're just putting on the GPU all we're really doing is telling the GPU where to check this type buffer for if a voxel exists so there's no reason we can do this also for air voxels right so instead of only looking at only telling the GPU to look at voxels that have a specific type we can also tell it to look at air so instead of having a mesh at all now we can use a single face for an entire slice of voxels and have that work and we make this work by instead of if we index into an air voxel all we have to do is discard that pixel and continue right so now we have a single phase for potentially 64 squared face every single time we don't have to mesh at all so we've gone from five milliseconds potentially to 0.01 milliseconds to nothing so it's really powerful right let's do this for an entire chunk our entire 64 Cube Chunk we can go from any number of binarily meshed greedy meshed faces down to a static 64 times six faces and we need that time six because we have positive and negative directions in every single axis X Y and Z so we have positive x negative X Etc but yeah we went from any number of faces down to 64 times six that's nothing right that's literally nothing basically let's use this for the entire world if we think about it for a second there's nothing stopping us from using these static faces for the entire world right so I call this the global lattice Global lattice because we have all these intersecting faces representing where every single possible voxel can exist and we can know where every single possible voxel exist because they exist on a uniform grid we know where every single phase can exist because they're all uniform in space which means we can just statically create a representation of our scene and basically render into it using this type buffer on the GPU so with a world size of 8192 by 255 by 8192 the binary greedy measure with that same like 8K height map loaded produces 35 million faces right but with a global lattice or our static mesh we only need 8192 times 4 plus 255 times 2 or 3 33 278 faces for the entire world so we've drastically reduced the amount of faces we need to represent our entire scene and more than that we don't even have to mesh anymore we don't have to spend any frame time at all meshing these chunks because we can use the static representation we know where every single possible we know every single possible combination of our world already so we can just represent that statically with even less data it's really powerful and we've kind of gone on this roundabout way of having to consider like meshing and speeds and all this stuff and complexity of our problem it's pretty complicated to do that bitwise thing I was talking about before to completely reasoning that part of the pipeline away right now we only have to have a static representation that we can do on Startup of faces that you can manually type the vertex positions for and use those right it's really powerful so yeah but it's not having to mesh mean instead of having to mesh every single time a voxel changes which could be like placing braking or having a voxel act on its own the change itself is the only update we need that simulation is the only update we need in memory uh besides coughing the type effort to the GPU because that is how we're defining if a voxel is going to be rendered or not right which we would have to do anyways before any part of our pipeline the ID needs to get to the GPU just so we can know if a voxel exists or it needs to be texture right and actually you can even do an optimization where you took a bid array uploaded that use that to test if it's Error and if it is air don't texture but if it's not error you should have an adjacent buffer that sparse with the types and then you could get those types so lots of optimizations here right so instead of having to worry about meshing at all the simulation is the update itself that means we could have massive worlds World updates and not worry about meshing we can set sdfs run large simulations like a huge game of life and do whatever we want basically and this is really powerful when you consider that also the only thing determining which voxels we're sampling is an index we have our chunk index and our voxel index and those combined tell us what voxel we're indexing so like I said with that rolling procedural World example if we load more chunks all we have to do is say hey are when we're meshing add this offset to our chunks right statistics so I've talked about statistics a lot but we took a 30 three to five milliseconds uh time to measure 64 cubed chunk with not reducing faces at all down to 0.12 milliseconds or 0.01 milliseconds in the best case scenario with binary greedy meshing then we realized we didn't have to mesh at all we didn't have to do any of this work in the end we've completely reasoned that away which is really I think it's cool yeah so let's solve some problems with the global lattice and also some and some optimizations let's let's first talk about a solution for floating Point Precision which I call the treadmill right with a rolling world that moves so quickly and such big faces representing our geometry like it could be zero to 8192 and when you're using World space positions to sample what type of voxel you are to mesh or to render sorry all we have to do we you know we run into floating Point positions very quickly because when you move further away from the origin or zero zero zero things get very janky very quickly so voxels will like lead into other voxels and it looks super awful so to fix this instead of actually moving the global lattice in the world and using the world space position to index um the chunks and which voxels we render all we have to do is let the player move in a single chunk at zero zero zero so they're always in this range and this is arbitrary it could be any region but we could just always have the player be in this like let's say it's just a single chunk of zero to 64 cubed and rolling in this chunk right so when a player crosses the chunk's boundary in any given direction we take which direction they moved in and turn that into a chunk indices using that same way we composed our chunk index we can just add 1 to X turn that into an index and add that to the chunk index that's being sampled on the GPU so we just add an offset based on the direction that they're going you can see that here since X was our first or our highest priority axis and constructing our index if they moved in the positive chunk direction of x uh we would just add one to the chunk index offset which would be added to the chunk index on the GPU that's being sampled so now the world is always located at zero zero zero it's local but we can still go through the entire world no problems but it's really powerful because now we don't have any floating Point position when we load noise so there's no like far lands if people are familiar with that term so now we can just have a truly infinite World it just we just have to generate the noise so another optimization I'd like to talk about is maximizing what's in view with frustum rotation right now at any given point the player is only seeing about two quadrants of our frustum or camera view the camera view is only looking into two-fourths of our actual Global lattice of our scene so an optimize it optimization we can do is let's say the player is looking in the bottom left corner what we can do is we can project where they're looking onto an inner boundary and almost flip the scenes that instead of looking out into the scene they're looking into the scene right so instead of only looking into two fourths of the of that frustum we could have them look into we can maximize the amount they're looking at at any given time based on their field of view so we can we can move that inner inner inner boundary there based on their fov so we can see that their fov is never going past this corner which means they can't see any like you know clipping in the world or you know edges right so it's just a seamless rule it just looks like it's infinite in that direction and if we haven't even and that's a pretty extreme fov so if you have an even lower F of V you know we can see that they're even closer to this border so instead of the player rotating around the center here we project where they're where they would be looking into and basically render the world back at them in a way so we're maximizing the amount of the global lattice that's being rendered at any given time right oh it's a really cool optimization so in conclusion I want to reflect on the kind of progress that we made while meshing and going through this entire process of optimization a lot of times we wouldn't even have made any progress or learned anything or found out that we could do better than we were doing if we didn't take a step back and think that we could do better so I want to mention that a lot of the time I think a lot more is possible than people realize or initially think and I think this is something that this taught me you know I was a beginner programmer around three years ago when I started making these voxel engines and I had a lot of preconceived ideas so I was holding on to this for a long time then eventually you just ask yourself wait a second why do I have to believe this and you can do so much more and the thing is it's not hard you just have to think you can do it I'm guarant there's like a thousand billion ideas that anyone in this room could absolutely pursue and find a lot more value there than that's than what's previously found right which is really cool like the end goal is never obvious if we if we never pursued the binary greedy meshing we would we would have never found out that we don't need to mesh at all right so I also want to encourage people to find a topic or technology that interests yourselves and to pursue that in this kind of in this kind of way see how far you can push it because a lot of the time it goes further than you might think and also when you pursue an idea like that you understand the problem very deeply which means you probably understand the computer very deeply right because that's hand in hand when you have that kind of relation you can take that specific your specific knowledge and generalize it to New problems where if you're working on something new and it's like oh this is kind of similar like that with that thing that I did over there and I know a lot about that thing so now I can take that very specific knowledge and apply it over there right so you know what parts of parts are fast and why allowing you to take your specific experience and use it to relate to new scenarios right so I kind of spread through that one but uh thank you all for listening uh I'm Davis Morley that's my Gmail if you want to contact me it's also my Twitter I think I'm supposed to turn it over to Abner for Q a yeah thank you [Applause]
